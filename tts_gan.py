# -*- coding: utf-8 -*-
"""TTS-GAN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N_bbj8rnYRwAxLfogkdk2WRKDC8sR5yo
"""

from google.colab import drive
drive.mount('/content/drive',force_remount=True)

! git clone https://github.com/imics-lab/tts-gan.git

# Commented out IPython magic to ensure Python compatibility.
# %cd tts-gan

# Commented out IPython magic to ensure Python compatibility.
# %ls

import pandas as pd
import numpy as np

import pandas as pd
import numpy as np
df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/subset_300.csv')
df = df[['machine_id' , 'time_stamp' , 'cpu_util_percent', 'mem_util_percent']]
tmp = df.groupby('machine_id').count().reset_index()
ids= tmp[(tmp['cpu_util_percent']==300) & (tmp['mem_util_percent']==300)]['machine_id']
ids = pd.DataFrame(ids)
df = df.merge(ids, on = 'machine_id')
sorted_df = df.groupby('machine_id').apply(lambda x: x.sort_values('time_stamp')).reset_index(drop=True)
sorted_df['col_index'] = sorted_df.groupby('machine_id').cumcount()

# # Pivot the DataFrame
pivot_df = sorted_df.pivot(index='machine_id', columns='col_index', values=['cpu_util_percent' , 'mem_util_percent'])
subsample = np.zeros([len(pivot_df) , 2,30])
for k in range(len(pivot_df)):
    for i in range(30):
        tmp = []
        tmp_mem = []
        for j in range((10*i), (10*i)+10):
            tmp.append(pivot_df['cpu_util_percent'].iloc[k , j])
            tmp_mem.append(pivot_df['mem_util_percent'].iloc[k , j])

        subsample[k , 0,i] = np.mean(tmp)
        subsample[k , 1,i] = np.mean(tmp_mem)

result = np.reshape(subsample , (len(subsample) , 2 ,30))
result_reshaped = np.reshape(result , (len(result) , 2 , 1 , 30))

# data = np.asarray([[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]])
# save to csv file


# self.x_train = result[:3000]
# self.x_test = result[3000:]
# # return(result)

azure data

import matplotlib.pyplot as plt

df = pd.read_csv('/content/drive/My Drive/Colab Notebooks/azure.csv')
df['timestamp'] =  pd.to_datetime(df['timestamp'])
df = df.set_index('timestamp')
# df = df.set_index('timestamp')
df.head()
df.plot(figsize=(16, 8))
plt.show()

plt.plot(reshaped_azure[0][0][0][:])

df.reset_index(inplace = True)
data =  np.asarray(df.iloc[:,1:5])
TRAIN_LENGTH = round(len(data)*0.9)
TEST_LENGTH = len(data) - TRAIN_LENGTH
train = data[0:TRAIN_LENGTH]
test = data[TRAIN_LENGTH : ]

def time_series_to_sequences(time_series, timesteps):
    '''
    Reshape the time series as sequences.
    '''
    sequences = np.array([time_series[t - timesteps: t] for t in range(timesteps, len(time_series) + timesteps, timesteps)])

    return sequences

x = time_series_to_sequences(time_series=data, timesteps=15)

data

def train_generator(dataset, n_lags=7):
    dataX = []
    for i in np.arange(0 , len(dataset)- n_lags -1, 3):
        a = dataset.iloc[i:(i+n_lags)].values
        dataX.append(a)
        # dataY.append(dataset.iloc[i + n_lags].to_numpy())
    return (np.array(dataX))

azdf = train_generator(pd.DataFrame(train), 30)
x = azdf

reshaped_azure = np.reshape(x , (len(x), np.shape(x)[2] , np.shape(x)[1]))
reshaped_azure = np.reshape(reshaped_azure , (len(x), np.shape(x)[2] ,1 ,  np.shape(x)[1]))

np.save('/content/drive/My Drive/Colab Notebooks/reshaped_azure', reshaped_azure)

azdf = np.load('/content/drive/My Drive/Colab Notebooks/reshaped_azure.npy', allow_pickle=True)

np.save('/content/drive/My Drive/Colab Notebooks/result_reshaped', result_reshaped)

rs = np.load('/content/drive/My Drive/Colab Notebooks/result_reshaped.npy', allow_pickle=True)

!pip install tsaug
!pip install einops

!python RunningGAN_Train.py -i reshaped_azure

np.save( '/content/drive/My Drive/Colab Notebooks/test_azure_tts_gan.npy', test)
# np.save('/content/drive/My Drive/Colab Notebooks/x_hat_azure.npy', x_hat )
np.save( '/content/drive/My Drive/Colab Notebooks/x_sim_azure_tts_gan.npy', x_sim)

sin1 = np.load( '/content/drive/My Drive/Colab Notebooks/x_sin_azure_tts_gan.npy' , allow_pickle = False)

sin1[1]

agg_alibaba = pd.read_csv('/content/drive/My Drive/Colab Notebooks/alibaba_machine.csv', index_col = 0)
result = np.reshape(np.asarray(agg_alibaba) , (np.shape(agg_alibaba)[0] , 1,1,np.shape(agg_alibaba)[1]))

TRAIN_LENGTH = round(len(agg_alibaba)*0.8)
TEST_LENGTH = len(agg_alibaba) - TRAIN_LENGTH
train = agg_alibaba[0:TRAIN_LENGTH]
test = agg_alibaba[TRAIN_LENGTH : ]

def train_generator(dataset, n_lags=7):
    dataX = []
    for i in np.arange(0 , len(dataset)- n_lags -1, 3):
        a = dataset.iloc[i:(i+n_lags)].values
        dataX.append(a)
        # dataY.append(dataset.iloc[i + n_lags].to_numpy())
    return (np.array(dataX))

azdf = train_generator(pd.DataFrame(train), 30)
x = azdf

np.shape(result)

result

uname = "niloofarsharifi95"
!git config --global user.email '$uname@gmail.com'
!git config --global user.name 'niloofar_sharifi'

!git checkout -b tt

!git status

# !git add .
!git push -u https://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@github.com/niloofarsharifi/RGAN.git tt

!git commit -m "azure added"